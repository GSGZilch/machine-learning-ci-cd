{
	"$schema": "http://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
	"contentVersion": "1.0.0.0",
	"parameters": {
		"workspaceName": {
			"type": "string",
			"metadata": "Workspace name",
			"defaultValue": "owm-syn-001"
		},
		"owm-syn-001-WorkspaceDefaultSqlServer_connectionString": {
			"type": "secureString",
			"metadata": "Secure string for 'connectionString' of 'owm-syn-001-WorkspaceDefaultSqlServer'"
		},
		"ls_kv_main_properties_typeProperties_baseUrl": {
			"type": "string",
			"defaultValue": "https://mlcicd-kv-001.vault.azure.net/"
		},
		"owm-syn-001-WorkspaceDefaultStorage_properties_typeProperties_url": {
			"type": "string",
			"defaultValue": "https://owmadls001.dfs.core.windows.net"
		}
	},
	"variables": {
		"workspaceId": "[concat('Microsoft.Synapse/workspaces/', parameters('workspaceName'))]"
	},
	"resources": [
		{
			"name": "[concat(parameters('workspaceName'), '/DevSmallCpu')]",
			"type": "Microsoft.Synapse/workspaces/bigDataPools",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": []
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/P01 - Data Ingestion')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "Ingest Weather Data",
						"type": "ExecutePipeline",
						"dependsOn": [],
						"userProperties": [],
						"typeProperties": {
							"pipeline": {
								"referenceName": "PL - Ingest Weather Data",
								"type": "PipelineReference"
							},
							"waitOnCompletion": true,
							"parameters": {
								"dateAndTimeOfImport": {
									"value": "@{formatDateTime(pipeline().TriggerTime, 'yyyy-MM-dd hh:mm:ss')}",
									"type": "Expression"
								}
							}
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"folder": {
					"name": "_LoadEntity"
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/pipelines/PL - Ingest Weather Data')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/P02 - Data Transformation')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "Concat Weather Data",
						"type": "ExecutePipeline",
						"dependsOn": [],
						"userProperties": [],
						"typeProperties": {
							"pipeline": {
								"referenceName": "PL - Concat Weather Data",
								"type": "PipelineReference"
							},
							"waitOnCompletion": true,
							"parameters": {
								"dateAndTimeOfImport": {
									"value": "@{formatDateTime(pipeline().TriggerTime, 'yyyy-MM-dd hh:mm:ss')}",
									"type": "Expression"
								}
							}
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"folder": {
					"name": "_LoadEntity"
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/pipelines/PL - Concat Weather Data')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/PL - Concat Weather Data')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "Concat Weather - Brussels",
						"type": "SynapseNotebook",
						"dependsOn": [],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"notebook": {
								"referenceName": "concat_daily_owm_data",
								"type": "NotebookReference"
							},
							"parameters": {
								"pipeline_trigger_time": {
									"value": {
										"value": "@pipeline().parameters.dateAndTimeOfImport",
										"type": "Expression"
									},
									"type": "string"
								},
								"location": {
									"value": {
										"value": "brussels",
										"type": "Expression"
									},
									"type": "string"
								}
							},
							"snapshot": true,
							"sparkPool": {
								"referenceName": "SparkSmallCpu",
								"type": "BigDataPoolReference"
							}
						}
					},
					{
						"name": "Concat Weather - Dublin",
						"type": "SynapseNotebook",
						"dependsOn": [],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"notebook": {
								"referenceName": "concat_daily_owm_data",
								"type": "NotebookReference"
							},
							"parameters": {
								"pipeline_trigger_time": {
									"value": {
										"value": "@pipeline().parameters.dateAndTimeOfImport",
										"type": "Expression"
									},
									"type": "string"
								},
								"location": {
									"value": {
										"value": "dublin",
										"type": "Expression"
									},
									"type": "string"
								}
							},
							"snapshot": true,
							"sparkPool": {
								"referenceName": "SparkSmallCpu",
								"type": "BigDataPoolReference"
							}
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"parameters": {
					"dateAndTimeOfImport": {
						"type": "string"
					}
				},
				"folder": {
					"name": "P02 - Data Transformation"
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/notebooks/concat_daily_owm_data')]",
				"[concat(variables('workspaceId'), '/bigDataPools/SparkSmallCpu')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/PL - Ingest Weather Data')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "Ingest Weather - Brussels",
						"type": "SynapseNotebook",
						"dependsOn": [],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"notebook": {
								"referenceName": "ingest_owm_data",
								"type": "NotebookReference"
							},
							"parameters": {
								"pipeline_trigger_time": {
									"value": {
										"value": "@pipeline().parameters.dateAndTimeOfImport",
										"type": "Expression"
									},
									"type": "string"
								},
								"location": {
									"value": {
										"value": "brussels",
										"type": "Expression"
									},
									"type": "string"
								}
							},
							"snapshot": true,
							"sparkPool": {
								"referenceName": "SparkSmallCpu",
								"type": "BigDataPoolReference"
							}
						}
					},
					{
						"name": "Ingest Weather - Dublin",
						"type": "SynapseNotebook",
						"dependsOn": [],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"notebook": {
								"referenceName": "ingest_owm_data",
								"type": "NotebookReference"
							},
							"parameters": {
								"pipeline_trigger_time": {
									"value": {
										"value": "@pipeline().parameters.dateAndTimeOfImport",
										"type": "Expression"
									},
									"type": "string"
								},
								"location": {
									"value": {
										"value": "dublin",
										"type": "Expression"
									},
									"type": "string"
								}
							},
							"snapshot": true,
							"sparkPool": {
								"referenceName": "SparkSmallCpu",
								"type": "BigDataPoolReference"
							}
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"parameters": {
					"dateAndTimeOfImport": {
						"type": "string"
					}
				},
				"folder": {
					"name": "P01 - Data Ingestion"
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/notebooks/ingest_owm_data')]",
				"[concat(variables('workspaceId'), '/bigDataPools/SparkSmallCpu')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/PL - Main')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "P01 - Data Ingestion",
						"type": "ExecutePipeline",
						"dependsOn": [],
						"userProperties": [],
						"typeProperties": {
							"pipeline": {
								"referenceName": "P01 - Data Ingestion",
								"type": "PipelineReference"
							},
							"waitOnCompletion": true,
							"parameters": {}
						}
					},
					{
						"name": "P02 - Data Transformation",
						"type": "ExecutePipeline",
						"dependsOn": [
							{
								"activity": "P01 - Data Ingestion",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"pipeline": {
								"referenceName": "P02 - Data Transformation",
								"type": "PipelineReference"
							},
							"waitOnCompletion": true,
							"parameters": {}
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/pipelines/P01 - Data Ingestion')]",
				"[concat(variables('workspaceId'), '/pipelines/P02 - Data Transformation')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/ls_kv_main')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureKeyVault",
				"typeProperties": {
					"baseUrl": "[parameters('ls_kv_main_properties_typeProperties_baseUrl')]"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/owm-syn-001-WorkspaceDefaultSqlServer')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"parameters": {
					"DBName": {
						"type": "String"
					}
				},
				"annotations": [],
				"type": "AzureSqlDW",
				"typeProperties": {
					"connectionString": "[parameters('owm-syn-001-WorkspaceDefaultSqlServer_connectionString')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/owm-syn-001-WorkspaceDefaultStorage')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureBlobFS",
				"typeProperties": {
					"url": "[parameters('owm-syn-001-WorkspaceDefaultStorage_properties_typeProperties_url')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/AutoResolveIntegrationRuntime')]",
			"type": "Microsoft.Synapse/workspaces/integrationRuntimes",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"type": "Managed",
				"typeProperties": {
					"computeProperties": {
						"location": "AutoResolve",
						"dataFlowProperties": {
							"computeType": "General",
							"coreCount": 8,
							"timeToLive": 0
						}
					}
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/WorkspaceSystemIdentity')]",
			"type": "Microsoft.Synapse/workspaces/credentials",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"type": "ManagedIdentity",
				"typeProperties": {}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/concat_daily_owm_data')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "P02 - Data Transformation"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "SparkSmallCpu",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "d0ee61a2-d4dd-4209-b400-bb4df32d7f74"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/c9a2b097-83d7-4ec1-8355-dbd181b27e99/resourceGroups/om-ml-ci-cd/providers/Microsoft.Synapse/workspaces/owm-syn-001/bigDataPools/SparkSmallCpu",
						"name": "SparkSmallCpu",
						"type": "Spark",
						"endpoint": "https://owm-syn-001.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/SparkSmallCpu",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.1",
						"nodeCount": 10,
						"cores": 4,
						"memory": 28
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"from datetime import timedelta"
						],
						"outputs": [],
						"execution_count": 40
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"tags": [
								"parameters"
							]
						},
						"source": [
							"# Parameter cell to define default values for notebook input parameters\r\n",
							"pipeline_trigger_time = \"2022-01-02 12:00:00\"\r\n",
							"location = \"brussels\""
						],
						"outputs": [],
						"execution_count": 33
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"%run _utils/pyspark_helper_functions"
						],
						"outputs": [],
						"execution_count": 34
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"dt = convert_to_dt(pipeline_trigger_time)\r\n",
							"\r\n",
							"dt_before = dt - timedelta(days=1)\r\n",
							"\r\n",
							"files = get_files_by_day(dt_before, location)\r\n",
							"\r\n",
							"folder_path = get_adls_folder_path(dt_before, location)\r\n",
							"\r\n",
							"dfs = [pyspark_read_csv(f\"{folder_path}/{file}\") for file in files]\r\n",
							"\r\n",
							"full_day_df = union_df_list(dfs)"
						],
						"outputs": [],
						"execution_count": 35
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"folder_path = get_adls_folder_path(dt_before, 'silver', location)\r\n",
							"\r\n",
							"write_dataframe(full_day_df, folder_path, partitions=1)"
						],
						"outputs": [],
						"execution_count": 41
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/ingest_owm_data')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "P01 - Data Ingestion"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "SparkSmallCpu",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "4a900755-0347-436e-a3b5-163add18fe37"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/c9a2b097-83d7-4ec1-8355-dbd181b27e99/resourceGroups/om-ml-ci-cd/providers/Microsoft.Synapse/workspaces/owm-syn-001/bigDataPools/SparkSmallCpu",
						"name": "SparkSmallCpu",
						"type": "Spark",
						"endpoint": "https://owm-syn-001.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/SparkSmallCpu",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.1",
						"nodeCount": 10,
						"cores": 4,
						"memory": 28
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"source": [
							"import requests\r\n",
							"from pyspark.sql.types import StructType, StructField, StringType, ArrayType, FloatType, IntegerType\r\n",
							"from pyspark.sql import SparkSession, Row\r\n",
							"from pyspark.sql.functions import *\r\n",
							"import json\r\n",
							"import pandas as pd\r\n",
							"from datetime import datetime"
						],
						"outputs": [],
						"execution_count": 84
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"tags": [
								"parameters"
							]
						},
						"source": [
							"# Parameter cell to define default values for notebook input parameters\r\n",
							"pipeline_trigger_time = \"2022-01-01 12:00:00\"\r\n",
							"location = \"brussels\""
						],
						"outputs": [],
						"execution_count": 83
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"%run _utils/location_mapping"
						],
						"outputs": [],
						"execution_count": 85
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"%run _utils/pyspark_helper_functions"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"key_vault_name = 'mlcicd-kv-001'\r\n",
							"\r\n",
							"api_endpoint = TokenLibrary.getSecret(key_vault_name, 'openweathermap-api-endpoint', 'ls_kv_main')\r\n",
							"api_key = TokenLibrary.getSecret(key_vault_name, 'openweathermap-api-key', 'ls_kv_main')\r\n",
							"\r\n",
							"lat = LOCATION_COORDS[location.upper()][\"lat\"]\r\n",
							"lon = LOCATION_COORDS[location.upper()][\"lon\"]\r\n",
							"\r\n",
							"params = {\r\n",
							"    \"lat\": lat,\r\n",
							"    \"lon\": lon,\r\n",
							"    \"appid\": api_key,\r\n",
							"    \"exclude\": \"minutely,hourly,daily\"\r\n",
							"}\r\n",
							"\r\n",
							"resp = requests.get(api_endpoint, params=params)\r\n",
							"data = resp.json()\r\n",
							"print(f\"Status code: {resp.status_code}. Reason: {resp.reason}.\")"
						],
						"outputs": [],
						"execution_count": 74
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"print(data)"
						],
						"outputs": [],
						"execution_count": 86
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"data[\"timestamp\"] = pipeline_trigger_time"
						],
						"outputs": [],
						"execution_count": 87
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"df = pd.json_normalize(data)\r\n",
							"df = df.explode('current.weather').to_dict(orient='records')\r\n",
							"df = pd.json_normalize(df)"
						],
						"outputs": [],
						"execution_count": 89
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"dt = convert_to_dt(pipeline_trigger_time)\r\n",
							"\r\n",
							"folder_path = get_adls_folder_path(dt, 'bronze', location)\r\n",
							"\r\n",
							"file_name = f\"weather_{dt.year}{dt.month:02d}{dt.day:02d}-{dt.hour:02d}{dt.minute:02d}{dt.second:02d}.csv\"\r\n",
							"\r\n",
							"output_path = f\"{folder_path}/{file_name}\"\r\n",
							"\r\n",
							"df.to_csv(output_path, index=False)"
						],
						"outputs": [],
						"execution_count": 90
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/location_mapping')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "_utils"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "997001d7-4384-4c07-bde8-b6ee017e2e7f"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "python"
					},
					"language_info": {
						"name": "python"
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"source": [
							"LOCATION_COORDS = {\r\n",
							"    \"BRUSSELS\": {\r\n",
							"        \"lat\": 50.846698,\r\n",
							"        \"lon\": 4.352522\r\n",
							"    },\r\n",
							"    \"DUBLIN\": {\r\n",
							"        \"lat\": 53.268889, \r\n",
							"        \"lon\": -6.196880\r\n",
							"    }\r\n",
							"}"
						],
						"outputs": [],
						"execution_count": null
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/pyspark_helper_functions')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "_utils"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "36873745-035c-4ed0-a483-b85e42c9a535"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "python"
					},
					"language_info": {
						"name": "python"
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"import os\r\n",
							"from datetime import datetime\r\n",
							"from pyspark.sql import SparkSession \r\n",
							"from pyspark.sql.types import * "
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"source": [
							"def pyspark_read_csv(path):\r\n",
							"    df = spark.read.load(path, \r\n",
							"        format='csv', \r\n",
							"        header=True)\r\n",
							"    return df"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def write_dataframe(df, path, partitions, csv=True, parquet=False, json=False):\r\n",
							"    df = df.repartition(partitions)\r\n",
							"\r\n",
							"    if csv: df.write.csv(f\"{path}csv/\", mode='overwrite', header = 'true') \r\n",
							"    if parquet: df.write.parquet(f\"{path}parquet/\", mode='overwrite') \r\n",
							"    if json: df.write.json(f\"{path}json/\", mode='overwrite')"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def get_adls_folder_path(dt, tier, location):\r\n",
							"    return f\"abfss://dataplatform@owmadls001.dfs.core.windows.net/{tier}/weather/{location.lower()}/{dt.year}/{dt.month:02d}/{dt.day:02d}\""
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def get_mounted_folder_path(dt, location, job_id):\r\n",
							"    return f\"/synfs/{job_id}/owmadls/bronze/weather/{location.lower()}/{dt.year}/{dt.month:02d}/{dt.day:02d}\""
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def convert_to_dt(dt_string):\r\n",
							"    return datetime.strptime(dt_string, \"%Y-%m-%d %H:%M:%S\")"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def get_files_by_day(dt, location):\r\n",
							"    try:\r\n",
							"        mssparkutils.fs.mount(\r\n",
							"        \"abfss://dataplatform@owmadls001.dfs.core.windows.net/\",\r\n",
							"        \"/owmadls\",\r\n",
							"        {\"linkedService\": \"owm-syn-001-WorkspaceDefaultStorage\"})\r\n",
							"    except:\r\n",
							"        pass\r\n",
							"\r\n",
							"    job_id = mssparkutils.env.getJobId()\r\n",
							"\r\n",
							"    folder_path = get_mounted_folder_path(dt, location, job_id)\r\n",
							"\r\n",
							"    if os.path.exists(folder_path)\r\n",
							"        return os.listdir(folder_path)\r\n",
							"    else:\r\n",
							"        return []"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def union_df_list(df_list):\r\n",
							"    df = df_list[0]\r\n",
							"    if len(df_list) > 1:\r\n",
							"        for next_df in df_list[1:]:\r\n",
							"            df = df.union(next_df)\r\n",
							"    return df"
						],
						"outputs": [],
						"execution_count": null
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/SparkSmallCpu')]",
			"type": "Microsoft.Synapse/workspaces/bigDataPools",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"autoPause": {
					"enabled": true,
					"delayInMinutes": 90
				},
				"autoScale": {
					"enabled": true,
					"maxNodeCount": 9,
					"minNodeCount": 3
				},
				"nodeCount": 10,
				"nodeSize": "Small",
				"nodeSizeFamily": "MemoryOptimized",
				"sparkVersion": "3.1",
				"isComputeIsolationEnabled": false,
				"sessionLevelPackagesEnabled": false,
				"annotations": []
			},
			"dependsOn": [],
			"location": "westeurope"
		},
		{
			"name": "[concat(parameters('workspaceName'), '/DevSmallCpu')]",
			"type": "Microsoft.Synapse/workspaces/bigDataPools",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"autoPause": {
					"enabled": true,
					"delayInMinutes": 60
				},
				"autoScale": {
					"enabled": true,
					"maxNodeCount": 3,
					"minNodeCount": 3
				},
				"nodeCount": 10,
				"nodeSize": "Small",
				"nodeSizeFamily": "MemoryOptimized",
				"sparkVersion": "3.1",
				"isComputeIsolationEnabled": false,
				"sessionLevelPackagesEnabled": false,
				"annotations": []
			},
			"dependsOn": [],
			"location": "westeurope"
		}
	]
}